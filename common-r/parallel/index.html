<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>Parallel programming - SC1</title>
    <meta property="og:title" content="Parallel programming - SC1">
    
    <meta name="twitter:card" content="summary">

    
      
    

    
      
      <meta property="description" content="Note. Any timing results here could be substantially different to what you would get if you ran the code on your own computer, so comments on the results may also be confusing. This is because these &amp;hellip;">
      <meta property="og:description" content="Note. Any timing results here could be substantially different to what you would get if you ran the code on your own computer, so comments on the results may also be confusing. This is because these &amp;hellip;">
      
    

    
    

    

    
    


<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.12.0/build/styles/github.min.css">



    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Arvo">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Marcellus">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">

<link rel="stylesheet" href="/sc1/css/style.css" />
<link rel="stylesheet" href="/sc1/css/fonts.css" />
<link rel="stylesheet" href="/sc1/css/custom.css" />

<link rel="icon" href="/sc1/favicon.ico" type="image/x-icon" />



























<nav class="breadcrumbs">
    
        <a href="https://awllee.github.io/sc1">home / </a>
    
        <a href="https://awllee.github.io/sc1/common-r/">common-r / </a>
    
        <a href="https://awllee.github.io/sc1/common-r/parallel/">parallel / </a>
    
</nav>

  </head>

  
  <body class="sc1">
    <header class="masthead">
      <h1><a href="/">SC1</a></h1>

<p class="tagline">Statistical Computing 1</p>

      <nav class="menu">
  <input id="menu-check" type="checkbox" hidden/>
  <label id="menu-label" for="menu-check" class="unselectable" hidden>
    <span class="icon close-icon">✕</span>
    <span class="icon open-icon">☰</span>
    <span class="text">Menu</span>
  </label>
  <ul>
  
  
  <li><a href="/sc1/">Home</a></li>
  
  <li><a href="/sc1/intro-r/">Intro to R</a></li>
  
  <li><a href="/sc1/reproducibility/">Reproducibility</a></li>
  
  <li><a href="/sc1/packages/">Packages</a></li>
  
  <li><a href="/sc1/common-r/">Common R</a></li>
  
  <li><a href="/sc1/functional-oo/">Functional / OO</a></li>
  
  <li><a href="/sc1/tidyverse/">Tidyverse</a></li>
  
  <li><a href="/sc1/profile-debug/">Performance / Bugs</a></li>
  
  <li><a href="/sc1/matrices/">Matrices</a></li>
  
  <li><a href="/sc1/optimization/">Optimization</a></li>
  
  <li><a href="/sc1/integration/">Integration</a></li>
  
  
  </ul>
</nav>

    </header>

    <article class="main">
      <header class="title">
      
<h1>Parallel programming</h1>

<h3>
</h3>
<hr>


      </header>








<p><em>Note</em>. Any timing results here could be substantially different to what you would get if you ran the code on your own computer, so comments on the results may also be confusing. This is because these computations are run in the cloud, as part of the website build process.</p>
<div id="why-parallel" class="section level2">
<h2>Why parallel?</h2>
<p>Often, for large data processing jobs, a single CPU core is not enough. Large computational jobs can be:</p>
<ul>
<li>cpu-bound: takes too much cpu time</li>
<li>memory-bound: takes too much memory</li>
<li>I/O-bound: takes too much time to read/write from disk</li>
<li>network-bound: Takes too much time to transfer across network</li>
</ul>
<p>Parallel programming aims to distribute cpu-bound computations to different cores (in a single processor) or processors (if available). Modern supercomputers are fast because they have massive number of processors, therefore it is crucial to be able write programs that run in parallel if one wants to take advantage of large clusters of processors.</p>
<p>However, it is not true, even for easily parallelisable computations, that running on <span class="math inline">\(n\)</span> processes will be <span class="math inline">\(n\)</span> times as fast. The achievable gain using additional processors tend to diminish as <span class="math inline">\(n\)</span> increases.</p>
</div>
<div id="parallelise-using-mclapply" class="section level2">
<h2>Parallelise using <code>mclapply</code></h2>
<pre class="r"><code>library(parallel)
num_cores &lt;- detectCores()
num_cores</code></pre>
<pre><code>## [1] 2</code></pre>
<p>In a Wright-Fisher model, an important model in population genetics, we trace the frequency of a mutant in a population of constant size <span class="math inline">\(N\)</span>. The number of mutants <span class="math inline">\(X_k\)</span> is a Markov process that depends only on the value of <span class="math inline">\(X_{k-1}\)</span>:
<span class="math display">\[ X_k | X_{k-1} \sim Binomial(N, \frac{X_{k-1}} N). \]</span></p>
<pre class="r"><code>simulate_wright_fisher &lt;- function(N, n_gen, init_freq) {
  # population size, number of generation to simulate, and initial frequency of mutant
  counts &lt;- numeric(n_gen)
  counts[1] &lt;- round(N * init_freq)
  for (k in 2:n_gen) {
    counts[k] &lt;- rbinom(1, size=N, prob=counts[k-1]/N)
  }
  return(counts)
}
counts &lt;- simulate_wright_fisher(5000, 10000, 0.2)
plot(counts, type=&#39;l&#39;, main=&#39;frequency of mutant&#39;, xlab=&#39;generation&#39;, ylab=&#39;&#39;)</code></pre>
<p><img src="/sc1common-r/parallel_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>system.time(simulate_wright_fisher(5000, 10000, 0.2))</code></pre>
<pre><code>##    user  system elapsed 
##   0.023   0.000   0.023</code></pre>
<p>This simple “neutral” Wright-Fisher model can still be vectorised relatively easily, but more complicated models won’t be. This is where parallelisation comes in.</p>
</div>
<div id="mclapply-doesnt-work-on-windows" class="section level2">
<h2><code>mclapply()</code> (doesn’t work on windows)</h2>
<pre class="r"><code>wrapper &lt;- function(init_freq) simulate_wright_fisher(5000, 10, init_freq)
init_freqs &lt;- rep(0.2, 3)
res &lt;- mclapply(init_freqs, wrapper, mc.cores=2)
res</code></pre>
<pre><code>## [[1]]
##  [1] 1000  955  925  934  953  962  929  894  876  868
## 
## [[2]]
##  [1] 1000  994  982  958  895  879  848  831  791  797
## 
## [[3]]
##  [1] 1000  996  987  962  949  956  974  988 1000 1046</code></pre>
<pre class="r"><code>wrapper2 &lt;- function(init_freq) tail(simulate_wright_fisher(5000, 1000, init_freq), 1)
init_freqs2 &lt;- rep(0.2, 500)
system.time(lapply(init_freqs2, wrapper2))</code></pre>
<pre><code>##    user  system elapsed 
##   1.303   0.012   1.315</code></pre>
<pre class="r"><code>system.time(mclapply(init_freqs2, wrapper2, mc.cores=2))</code></pre>
<pre><code>##    user  system elapsed 
##   0.001   0.004   0.717</code></pre>
<pre class="r"><code>system.time(mclapply(init_freqs2, wrapper2, mc.cores=4))</code></pre>
<pre><code>##    user  system elapsed 
##   0.712   0.104   0.809</code></pre>
<p>The results show that <code>mclapply</code> with 2 cores is twice as fast as <code>lapply</code>. Increasing to 4 cores improves the performance of <code>mclapply</code> further, but by a factor slightly less than 2. (Note that on this MacBook, there are 4 physical cores, 8 virtual cores.)</p>
</div>
<div id="foreach-and-doparallel" class="section level2">
<h2><code>foreach</code> and <code>doParallel</code></h2>
<p>Note that <code>foreach</code> is not a parallel for loop. It resembles a function that outputs something, typically a list of the same length as the number of iterates, with usage illustrated below. Note that <code>%do%</code> evaluates the expression sequentially, while <code>%dopar%</code> evaluates it in parallel.</p>
<pre class="r"><code>library(foreach)
foreach (i=1:3) %do% {
  i*i
}</code></pre>
<pre><code>## [[1]]
## [1] 1
## 
## [[2]]
## [1] 4
## 
## [[3]]
## [1] 9</code></pre>
<pre class="r"><code>res &lt;- foreach (i=1:2, .combine=rbind) %do% {
  simulate_wright_fisher(5000, 10, 0.2)
}
res</code></pre>
<pre><code>##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## result.1 1000  967  926  925  926  943  936  939  926   902
## result.2 1000 1029 1003  988 1032 1009 1015  988 1007   989</code></pre>
<p>A useful argument to add to <code>foreach</code> is <code>.final</code>, which is function of one argument that is called to return final. For sample, if we are only interested in the number of mutants in the most recent generation,</p>
<pre class="r"><code>n_gen &lt;- 1000
res &lt;- foreach (i=1:1000, .combine=rbind, .final=function(x) x[,n_gen]) %do% {
  simulate_wright_fisher(5000, n_gen, 0.2)
}
hist(res, breaks=50)</code></pre>
<p><img src="/sc1common-r/parallel_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>So far nothing has run in parallel. In order to do so, we need to register the number of cores to use via <code>registerDoParallel</code>.</p>
<pre class="r"><code>library(doParallel)</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre class="r"><code>registerDoParallel(2) # only register 2 cores
n_runs &lt;- 200
system.time(foreach (i=1:n_runs, .combine=rbind, .final=function(x) x[,n_gen]) %do% {
  simulate_wright_fisher(5000, n_gen, 0.2)
})</code></pre>
<pre><code>##    user  system elapsed 
##   0.549   0.000   0.549</code></pre>
<pre class="r"><code>system.time(foreach (i=1:n_runs, .combine=rbind, .final=function(x) x[,n_gen]) %dopar% {
  simulate_wright_fisher(5000, n_gen, 0.2)
})</code></pre>
<pre><code>##    user  system elapsed 
##   0.616   0.114   0.377</code></pre>
<pre class="r"><code>t1 &lt;- Sys.time()
res1 &lt;- foreach (i=1:n_runs, .combine=rbind, .final=function(x) x[,n_gen]) %do% {
  simulate_wright_fisher(5000, n_gen, 0.2)
}
t2 &lt;- Sys.time()
res2 &lt;- foreach (i=1:n_runs, .combine=rbind, .final=function(x) x[,n_gen]) %dopar% {
  simulate_wright_fisher(5000, n_gen, 0.2)
}
t3 &lt;- Sys.time()
registerDoParallel(4) # try registering all 4 cores
res2 &lt;- foreach (i=1:n_runs, .combine=rbind, .final=function(x) x[,n_gen]) %dopar% {
  simulate_wright_fisher(5000, n_gen, 0.2)
}
t4 &lt;- Sys.time()

t2-t1</code></pre>
<pre><code>## Time difference of 0.577471 secs</code></pre>
<pre class="r"><code>t3-t2</code></pre>
<pre><code>## Time difference of 0.4573038 secs</code></pre>
<pre class="r"><code>t4-t3</code></pre>
<pre><code>## Time difference of 0.6398735 secs</code></pre>
<pre class="r"><code># clean up the cluster
stopImplicitCluster()</code></pre>
<p>Just as in the case of <code>mclapply</code>, evaluating the code in parallel with 2 cores takes about half as much time as evaluating the code sequentially, but with 4 cores, the speedup deteriorates somewhat.</p>
</div>



  <footer>
  

<script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>


<script type="text/javascript">
var sc_project=12110974;
var sc_invisible=1;
var sc_security="9b171880";
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12110974/0/9b171880/1/"
alt="Web Analytics"></a></div></noscript>








  


<p align=right>

<a href='https://github.com/awllee/sc1/blob/master/content/common-r/parallel.Rmd'>View source</a>

|

<a href='https://github.com/awllee/sc1/edit/master/content/common-r/parallel.Rmd'>Edit source</a>

</p>





<script src="https://utteranc.es/client.js"
        repo="awllee/sc1"
        issue-term="pathname"
        label="utterance"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>



  











<script src="//cdn.jsdelivr.net/combine/gh/highlightjs/cdn-release@9.12.0/build/highlight.min.js,gh/highlightjs/cdn-release@9.12.0/build/languages/r.min.js,gh/highlightjs/cdn-release@9.12.0/build/languages/yaml.min.js,gh/highlightjs/cdn-release@9.12.0/build/languages/tex.min.js,npm/@xiee/utils/js/load-highlight.js" defer></script>



  
  <hr>
  <div class="copyright">© 2020 <a href="https://sites.google.com/view/anthonylee">Anthony Lee</a>, <a href="http://www.bristol.ac.uk/maths/people/feng-yu/index.html">Feng Yu</a>, <a href="https://people.maths.bris.ac.uk/~tk18582/">Tobias Kley</a>, <a href="https://mfasiolo.github.io/">Matteo Fasiolo</a></div>
  
  </footer>
  </article>
  
  </body>
</html>

